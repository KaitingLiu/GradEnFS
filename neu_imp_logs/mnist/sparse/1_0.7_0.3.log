*************************************************arguments*************************************************
Namespace(alpha=0.3, batch=10, batch_update=False, beta=0.7, class_sep=1.0, dataset='mnist', detail=False, device='cpu', epoch=100, epsilon=1, evaluating_batch_size=10000, flip_y=0.01, hidden_dim=1000, input_dim=784, k_list=[100], logs_name='./neu_imp_logs/mnist/sparse/1_0.7_0.3.log', lr=0.001, n_classes=2, n_clusters_per_class=1, n_features=500, n_informative=5, n_redundant=15, n_samples=1000, network='sparse', num_testing=100, num_training=1000, num_validation=100, output_dim=10, random_state=0, repeat=1, results_name='./neu_imp_results/mnist/sparse/1_0.7_0.3.json', seeds=[0, 1, 2, 3, 4], shuffle=False, training_batch_size=100, use_seeds=False)
*************************************************Repeat 1*************************************************
Neural Network:
fc1.weight number of parameters(dense counterpart):784000 number of parameters(network topology):1729 density:0.002276 sparsity:0.997724
fc2.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):1950 density:0.002000 sparsity:0.998000
fc3.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):2010 density:0.002000 sparsity:0.998000
fc4.weight number of parameters(dense counterpart):10000 number of parameters(network topology):1071 density:0.101000 sparsity:0.899000
the entire network number of parameters(dense counterpart):2794000 number of parameters(network topology):6760 overall density:0.002419 overall sparsity:0.997581
successfully initialize neuron importance scores for every input neurons.
Epoch 1 Loss: 2.285107 Validation Accuracy: 0.140000
Epoch 2 Loss: 2.263171 Validation Accuracy: 0.140000
Epoch 3 Loss: 2.236958 Validation Accuracy: 0.140000
Epoch 4 Loss: 2.192282 Validation Accuracy: 0.140000
Epoch 5 Loss: 2.129156 Validation Accuracy: 0.140000
Epoch 6 Loss: 2.071010 Validation Accuracy: 0.190000
Epoch 7 Loss: 2.023978 Validation Accuracy: 0.370000
Epoch 8 Loss: 1.977898 Validation Accuracy: 0.640000
Epoch 9 Loss: 1.919919 Validation Accuracy: 0.730000
Epoch 10 Loss: 1.865023 Validation Accuracy: 0.750000
Epoch 11 Loss: 1.821017 Validation Accuracy: 0.760000
Epoch 12 Loss: 1.775869 Validation Accuracy: 0.760000
Epoch 13 Loss: 1.746801 Validation Accuracy: 0.740000
Epoch 14 Loss: 1.718990 Validation Accuracy: 0.720000
Epoch 15 Loss: 1.696542 Validation Accuracy: 0.710000
Epoch 16 Loss: 1.675508 Validation Accuracy: 0.690000
Epoch 17 Loss: 1.657660 Validation Accuracy: 0.660000
Epoch 18 Loss: 1.648818 Validation Accuracy: 0.790000
Epoch 19 Loss: 1.633586 Validation Accuracy: 0.780000
Epoch 20 Loss: 1.622731 Validation Accuracy: 0.750000
Epoch 21 Loss: 1.612471 Validation Accuracy: 0.820000
Epoch 22 Loss: 1.608755 Validation Accuracy: 0.860000
Epoch 23 Loss: 1.595971 Validation Accuracy: 0.870000
Epoch 24 Loss: 1.596176 Validation Accuracy: 0.870000
Epoch 25 Loss: 1.581817 Validation Accuracy: 0.880000
Epoch 26 Loss: 1.579827 Validation Accuracy: 0.850000
Epoch 27 Loss: 1.579090 Validation Accuracy: 0.750000
Epoch 28 Loss: 1.572937 Validation Accuracy: 0.810000
Epoch 29 Loss: 1.569016 Validation Accuracy: 0.850000
Epoch 30 Loss: 1.565791 Validation Accuracy: 0.860000
Epoch 31 Loss: 1.562532 Validation Accuracy: 0.790000
Epoch 32 Loss: 1.558724 Validation Accuracy: 0.840000
Epoch 33 Loss: 1.555833 Validation Accuracy: 0.880000
Epoch 34 Loss: 1.552184 Validation Accuracy: 0.870000
Epoch 35 Loss: 1.553479 Validation Accuracy: 0.860000
Epoch 36 Loss: 1.549716 Validation Accuracy: 0.640000
Epoch 37 Loss: 1.544621 Validation Accuracy: 0.820000
Epoch 38 Loss: 1.545369 Validation Accuracy: 0.910000
Epoch 39 Loss: 1.544655 Validation Accuracy: 0.890000
Epoch 40 Loss: 1.541249 Validation Accuracy: 0.810000
Epoch 41 Loss: 1.539654 Validation Accuracy: 0.760000
Epoch 42 Loss: 1.537229 Validation Accuracy: 0.840000
Epoch 43 Loss: 1.539490 Validation Accuracy: 0.910000
Epoch 44 Loss: 1.535325 Validation Accuracy: 0.870000
Epoch 45 Loss: 1.535641 Validation Accuracy: 0.920000
Epoch 46 Loss: 1.532420 Validation Accuracy: 0.930000
Epoch 47 Loss: 1.530681 Validation Accuracy: 0.920000
Epoch 48 Loss: 1.527933 Validation Accuracy: 0.890000
Epoch 49 Loss: 1.527656 Validation Accuracy: 0.820000
Epoch 50 Loss: 1.524688 Validation Accuracy: 0.880000
Epoch 51 Loss: 1.524901 Validation Accuracy: 0.880000
Epoch 52 Loss: 1.522364 Validation Accuracy: 0.870000
Epoch 53 Loss: 1.521764 Validation Accuracy: 0.890000
Epoch 54 Loss: 1.521216 Validation Accuracy: 0.880000
Epoch 55 Loss: 1.520331 Validation Accuracy: 0.880000
Epoch 56 Loss: 1.520475 Validation Accuracy: 0.890000
Epoch 57 Loss: 1.518459 Validation Accuracy: 0.890000
Epoch 58 Loss: 1.518363 Validation Accuracy: 0.890000
Epoch 59 Loss: 1.514589 Validation Accuracy: 0.910000
Epoch 60 Loss: 1.514948 Validation Accuracy: 0.890000
Epoch 61 Loss: 1.515022 Validation Accuracy: 0.890000
Epoch 62 Loss: 1.514929 Validation Accuracy: 0.890000
Epoch 63 Loss: 1.514583 Validation Accuracy: 0.900000
Epoch 64 Loss: 1.512187 Validation Accuracy: 0.950000
Epoch 65 Loss: 1.513093 Validation Accuracy: 0.870000
Epoch 66 Loss: 1.512324 Validation Accuracy: 0.870000
Epoch 67 Loss: 1.511454 Validation Accuracy: 0.850000
Epoch 68 Loss: 1.509621 Validation Accuracy: 0.900000
Epoch 69 Loss: 1.509320 Validation Accuracy: 0.920000
Epoch 70 Loss: 1.509340 Validation Accuracy: 0.870000
Epoch 71 Loss: 1.510009 Validation Accuracy: 0.910000
Epoch 72 Loss: 1.506737 Validation Accuracy: 0.910000
Epoch 73 Loss: 1.506421 Validation Accuracy: 0.880000
Epoch 74 Loss: 1.504483 Validation Accuracy: 0.860000
Epoch 75 Loss: 1.505033 Validation Accuracy: 0.900000
Epoch 76 Loss: 1.503090 Validation Accuracy: 0.900000
Epoch 77 Loss: 1.503009 Validation Accuracy: 0.850000
Epoch 78 Loss: 1.503133 Validation Accuracy: 0.890000
Epoch 79 Loss: 1.501302 Validation Accuracy: 0.930000
Epoch 80 Loss: 1.503559 Validation Accuracy: 0.930000
Epoch 81 Loss: 1.502076 Validation Accuracy: 0.930000
Epoch 82 Loss: 1.500947 Validation Accuracy: 0.910000
Epoch 83 Loss: 1.500294 Validation Accuracy: 0.890000
Epoch 84 Loss: 1.500489 Validation Accuracy: 0.910000
Epoch 85 Loss: 1.500353 Validation Accuracy: 0.920000
Epoch 86 Loss: 1.499880 Validation Accuracy: 0.920000
Epoch 87 Loss: 1.498876 Validation Accuracy: 0.890000
Epoch 88 Loss: 1.499464 Validation Accuracy: 0.890000
Epoch 89 Loss: 1.499383 Validation Accuracy: 0.890000
Epoch 90 Loss: 1.499442 Validation Accuracy: 0.940000
Epoch 91 Loss: 1.498682 Validation Accuracy: 0.930000
Epoch 92 Loss: 1.499250 Validation Accuracy: 0.930000
Epoch 93 Loss: 1.498590 Validation Accuracy: 0.910000
Epoch 94 Loss: 1.497100 Validation Accuracy: 0.940000
Epoch 95 Loss: 1.498380 Validation Accuracy: 0.950000
Epoch 96 Loss: 1.497243 Validation Accuracy: 0.950000
Epoch 97 Loss: 1.497654 Validation Accuracy: 0.850000
Epoch 98 Loss: 1.497601 Validation Accuracy: 0.860000
Epoch 99 Loss: 1.497556 Validation Accuracy: 0.870000
Stop random regrow in the last batch 100 of the last epoch 10
Epoch 100 Loss: 1.496588 Validation Accuracy: 0.880000
Test accuracy of the final network: 0.74
Statistic of the proposed dynamic method:
The SVM accuracy is 0.64 for 100 features in sparse network
Statistic of the static method:
The SVM accuracy is 0.76 for 100 features in sparse network
Statistic of the QS method:
The SVM accuracy is 0.76 for 100 features in sparse network
