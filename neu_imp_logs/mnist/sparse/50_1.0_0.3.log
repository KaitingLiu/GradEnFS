*************************************************arguments*************************************************
Namespace(alpha=0.3, batch=54, batch_update=True, beta=1.0, class_sep=1.0, dataset='mnist', detail=False, device='cpu', epoch=100, epsilon=50, evaluating_batch_size=10000, flip_y=0.01, hidden_dim=1000, input_dim=784, k_list=[25, 50, 75, 100, 150, 200], logs_name='./neu_imp_logs/mnist/sparse/50_1.0_0.3.log', lr=0.001, n_classes=2, n_clusters_per_class=1, n_features=500, n_informative=5, n_redundant=15, n_samples=1000, network='sparse', num_testing=1000, num_training=5400, num_validation=600, output_dim=10, random_state=0, repeat=1, results_name='./neu_imp_results/mnist/sparse/50_1.0_0.3.json', seeds=[0, 1, 2, 3, 4], shuffle=False, training_batch_size=100, use_seeds=False)
*************************************************Repeat 1*************************************************
Neural Network:
fc1.weight number of parameters(dense counterpart):784000 number of parameters(network topology):88865 density:0.113776 sparsity:0.886224
fc2.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):100185 density:0.100000 sparsity:0.900000
fc3.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):99822 density:0.100000 sparsity:0.900000
fc4.weight number of parameters(dense counterpart):10000 number of parameters(network topology):10000 density:1.000000 sparsity:0.000000
the entire network number of parameters(dense counterpart):2794000 number of parameters(network topology):298872 overall density:0.106969 overall sparsity:0.893031
successfully initialize neuron importance scores for every input neurons.
Epoch 1 Loss: 1.527685 Validation Accuracy: 0.955000
Epoch 2 Loss: 1.488094 Validation Accuracy: 0.950000
Epoch 3 Loss: 1.475921 Validation Accuracy: 0.966667
Epoch 4 Loss: 1.472634 Validation Accuracy: 0.956667
Epoch 5 Loss: 1.475811 Validation Accuracy: 0.965000
Epoch 6 Loss: 1.471447 Validation Accuracy: 0.960000
Epoch 7 Loss: 1.480634 Validation Accuracy: 0.953333
Epoch 8 Loss: 1.480282 Validation Accuracy: 0.958333
Epoch 9 Loss: 1.476642 Validation Accuracy: 0.961667
Epoch 10 Loss: 1.471263 Validation Accuracy: 0.956667
Epoch 11 Loss: 1.461464 Validation Accuracy: 0.963333
Epoch 12 Loss: 1.461228 Validation Accuracy: 0.965000
Epoch 13 Loss: 1.461836 Validation Accuracy: 0.966667
Epoch 14 Loss: 1.461226 Validation Accuracy: 0.961667
Epoch 15 Loss: 1.462317 Validation Accuracy: 0.965000
Epoch 16 Loss: 1.461392 Validation Accuracy: 0.958333
Epoch 17 Loss: 1.461654 Validation Accuracy: 0.956667
Epoch 18 Loss: 1.466954 Validation Accuracy: 0.958333
Epoch 19 Loss: 1.463257 Validation Accuracy: 0.945000
Epoch 20 Loss: 1.471813 Validation Accuracy: 0.946667
Epoch 21 Loss: 1.462788 Validation Accuracy: 0.950000
Epoch 22 Loss: 1.462118 Validation Accuracy: 0.953333
Epoch 23 Loss: 1.461596 Validation Accuracy: 0.958333
Epoch 24 Loss: 1.461278 Validation Accuracy: 0.960000
Epoch 25 Loss: 1.461200 Validation Accuracy: 0.966667
Epoch 26 Loss: 1.461360 Validation Accuracy: 0.961667
Epoch 27 Loss: 1.461204 Validation Accuracy: 0.963333
Epoch 28 Loss: 1.461161 Validation Accuracy: 0.965000
Epoch 29 Loss: 1.461160 Validation Accuracy: 0.965000
Epoch 30 Loss: 1.461159 Validation Accuracy: 0.965000
Epoch 31 Loss: 1.461158 Validation Accuracy: 0.965000
Epoch 32 Loss: 1.461158 Validation Accuracy: 0.965000
Epoch 33 Loss: 1.461157 Validation Accuracy: 0.965000
Epoch 34 Loss: 1.461156 Validation Accuracy: 0.965000
Epoch 35 Loss: 1.461156 Validation Accuracy: 0.965000
Epoch 36 Loss: 1.461156 Validation Accuracy: 0.965000
Epoch 37 Loss: 1.461156 Validation Accuracy: 0.965000
Epoch 38 Loss: 1.461156 Validation Accuracy: 0.965000
Epoch 39 Loss: 1.461156 Validation Accuracy: 0.965000
Epoch 40 Loss: 1.461156 Validation Accuracy: 0.965000
Epoch 41 Loss: 1.461155 Validation Accuracy: 0.966667
Epoch 42 Loss: 1.461155 Validation Accuracy: 0.968333
Epoch 43 Loss: 1.461155 Validation Accuracy: 0.966667
Epoch 44 Loss: 1.461155 Validation Accuracy: 0.965000
Epoch 45 Loss: 1.461154 Validation Accuracy: 0.965000
Epoch 46 Loss: 1.461154 Validation Accuracy: 0.966667
Epoch 47 Loss: 1.461154 Validation Accuracy: 0.966667
Epoch 48 Loss: 1.461154 Validation Accuracy: 0.966667
Epoch 49 Loss: 1.461154 Validation Accuracy: 0.965000
Epoch 50 Loss: 1.461154 Validation Accuracy: 0.965000
Epoch 51 Loss: 1.461154 Validation Accuracy: 0.963333
Epoch 52 Loss: 1.461175 Validation Accuracy: 0.963333
Epoch 53 Loss: 1.461156 Validation Accuracy: 0.961667
Epoch 54 Loss: 1.461155 Validation Accuracy: 0.961667
Epoch 55 Loss: 1.461155 Validation Accuracy: 0.963333
Epoch 56 Loss: 1.461155 Validation Accuracy: 0.965000
Epoch 57 Loss: 1.461154 Validation Accuracy: 0.963333
Epoch 58 Loss: 1.461154 Validation Accuracy: 0.961667
Epoch 59 Loss: 1.461154 Validation Accuracy: 0.963333
Epoch 60 Loss: 1.461154 Validation Accuracy: 0.966667
Epoch 61 Loss: 1.461154 Validation Accuracy: 0.966667
Epoch 62 Loss: 1.461154 Validation Accuracy: 0.966667
Epoch 63 Loss: 1.461154 Validation Accuracy: 0.966667
Epoch 64 Loss: 1.461154 Validation Accuracy: 0.966667
Epoch 65 Loss: 1.461154 Validation Accuracy: 0.966667
Epoch 66 Loss: 1.461154 Validation Accuracy: 0.963333
Epoch 67 Loss: 1.461154 Validation Accuracy: 0.963333
Epoch 68 Loss: 1.461154 Validation Accuracy: 0.965000
Epoch 69 Loss: 1.461153 Validation Accuracy: 0.966667
Epoch 70 Loss: 1.461153 Validation Accuracy: 0.965000
Epoch 71 Loss: 1.461153 Validation Accuracy: 0.963333
Epoch 72 Loss: 1.461153 Validation Accuracy: 0.965000
Epoch 73 Loss: 1.461153 Validation Accuracy: 0.966667
Epoch 74 Loss: 1.461153 Validation Accuracy: 0.966667
Epoch 75 Loss: 1.461153 Validation Accuracy: 0.966667
Epoch 76 Loss: 1.461153 Validation Accuracy: 0.966667
Epoch 77 Loss: 1.461153 Validation Accuracy: 0.966667
Epoch 78 Loss: 1.461152 Validation Accuracy: 0.966667
Epoch 79 Loss: 1.461152 Validation Accuracy: 0.966667
Epoch 80 Loss: 1.461153 Validation Accuracy: 0.966667
Epoch 81 Loss: 1.461152 Validation Accuracy: 0.970000
Epoch 82 Loss: 1.461152 Validation Accuracy: 0.970000
Epoch 83 Loss: 1.461153 Validation Accuracy: 0.970000
Epoch 84 Loss: 1.461153 Validation Accuracy: 0.971667
Epoch 85 Loss: 1.486972 Validation Accuracy: 0.898333
Epoch 86 Loss: 1.548351 Validation Accuracy: 0.921667
Epoch 87 Loss: 1.529308 Validation Accuracy: 0.940000
Epoch 88 Loss: 1.490297 Validation Accuracy: 0.958333
Epoch 89 Loss: 1.481257 Validation Accuracy: 0.965000
Epoch 90 Loss: 1.467305 Validation Accuracy: 0.965000
Epoch 91 Loss: 1.461431 Validation Accuracy: 0.956667
Epoch 92 Loss: 1.461339 Validation Accuracy: 0.965000
Epoch 93 Loss: 1.461167 Validation Accuracy: 0.956667
Epoch 94 Loss: 1.461158 Validation Accuracy: 0.958333
Epoch 95 Loss: 1.461152 Validation Accuracy: 0.956667
Epoch 96 Loss: 1.461179 Validation Accuracy: 0.956667
Epoch 97 Loss: 1.461151 Validation Accuracy: 0.963333
Epoch 98 Loss: 1.461153 Validation Accuracy: 0.963333
Epoch 99 Loss: 1.461151 Validation Accuracy: 0.966667
Stop random regrow in the last batch 100 of the last epoch 54
Epoch 100 Loss: 1.461151 Validation Accuracy: 0.965000
Test accuracy of the final network: 0.958
Statistic of the proposed dynamic method:
The SVM accuracy is 0.701 for 25 features in sparse network
The SVM accuracy is 0.832 for 50 features in sparse network
The SVM accuracy is 0.878 for 75 features in sparse network
The SVM accuracy is 0.913 for 100 features in sparse network
The SVM accuracy is 0.927 for 150 features in sparse network
The SVM accuracy is 0.943 for 200 features in sparse network
Statistic of the static method:
The SVM accuracy is 0.413 for 25 features in sparse network
The SVM accuracy is 0.682 for 50 features in sparse network
The SVM accuracy is 0.792 for 75 features in sparse network
The SVM accuracy is 0.841 for 100 features in sparse network
The SVM accuracy is 0.913 for 150 features in sparse network
The SVM accuracy is 0.937 for 200 features in sparse network
Statistic of the QS method:
The SVM accuracy is 0.127 for 25 features in sparse network
The SVM accuracy is 0.169 for 50 features in sparse network
The SVM accuracy is 0.207 for 75 features in sparse network
The SVM accuracy is 0.266 for 100 features in sparse network
The SVM accuracy is 0.571 for 150 features in sparse network
The SVM accuracy is 0.791 for 200 features in sparse network
