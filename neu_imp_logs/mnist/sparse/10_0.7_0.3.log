*************************************************arguments*************************************************
Namespace(alpha=0.3, batch=54, batch_update=False, beta=0.7, class_sep=1.0, dataset='mnist', detail=False, device='cpu', epoch=10, epsilon=10, evaluating_batch_size=10000, flip_y=0.01, hidden_dim=1000, input_dim=784, k_list=[100], logs_name='./neu_imp_logs/mnist/sparse/10_0.7_0.3.log', lr=0.001, n_classes=2, n_clusters_per_class=1, n_features=500, n_informative=5, n_redundant=15, n_samples=1000, network='sparse', num_testing=1000, num_training=5400, num_validation=600, output_dim=10, random_state=0, repeat=2, results_name='./neu_imp_results/mnist/sparse/10_0.7_0.3.json', seeds=[0, 1, 2, 3, 4], shuffle=False, training_batch_size=100, use_seeds=False)
*************************************************Repeat 1*************************************************
Neural Network:
fc1.weight number of parameters(dense counterpart):784000 number of parameters(network topology):17766 density:0.022755 sparsity:0.977245
fc2.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):20276 density:0.020000 sparsity:0.980000
fc3.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):20191 density:0.020000 sparsity:0.980000
fc4.weight number of parameters(dense counterpart):10000 number of parameters(network topology):10000 density:1.000000 sparsity:0.000000
the entire network number of parameters(dense counterpart):2794000 number of parameters(network topology):68233 overall density:0.024421 overall sparsity:0.975579
successfully initialize neuron importance scores for every input neurons.
Epoch 1 Loss: 1.658350 Validation Accuracy: 0.723333
Epoch 2 Loss: 1.555224 Validation Accuracy: 0.918333
Epoch 3 Loss: 1.531286 Validation Accuracy: 0.925000
Epoch 4 Loss: 1.515360 Validation Accuracy: 0.931667
Epoch 5 Loss: 1.511816 Validation Accuracy: 0.931667
Epoch 6 Loss: 1.507079 Validation Accuracy: 0.936667
Epoch 7 Loss: 1.501104 Validation Accuracy: 0.946667
Epoch 8 Loss: 1.501191 Validation Accuracy: 0.945000
Epoch 9 Loss: 1.503405 Validation Accuracy: 0.948333
Stop random regrow in the last batch 10 of the last epoch 54
Epoch 10 Loss: 1.502599 Validation Accuracy: 0.945000
Test accuracy of the final network: 0.964
Statistic of the proposed dynamic method:
The SVM accuracy is 0.934 for 100 features in sparse network
Statistic of the static method:
The SVM accuracy is 0.926 for 100 features in sparse network
Statistic of the QS method:
The SVM accuracy is 0.909 for 100 features in sparse network
*************************************************Repeat 2*************************************************
Neural Network:
fc1.weight number of parameters(dense counterpart):784000 number of parameters(network topology):18220 density:0.022755 sparsity:0.977245
fc2.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):20126 density:0.020000 sparsity:0.980000
fc3.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):20029 density:0.020000 sparsity:0.980000
fc4.weight number of parameters(dense counterpart):10000 number of parameters(network topology):10000 density:1.000000 sparsity:0.000000
the entire network number of parameters(dense counterpart):2794000 number of parameters(network topology):68375 overall density:0.024472 overall sparsity:0.975528
successfully initialize neuron importance scores for every input neurons.
Epoch 1 Loss: 1.617869 Validation Accuracy: 0.755000
Epoch 2 Loss: 1.543821 Validation Accuracy: 0.918333
Epoch 3 Loss: 1.520903 Validation Accuracy: 0.921667
Epoch 4 Loss: 1.505497 Validation Accuracy: 0.925000
Epoch 5 Loss: 1.506224 Validation Accuracy: 0.930000
Epoch 6 Loss: 1.501939 Validation Accuracy: 0.943333
Epoch 7 Loss: 1.497166 Validation Accuracy: 0.941667
Epoch 8 Loss: 1.491639 Validation Accuracy: 0.945000
Epoch 9 Loss: 1.491264 Validation Accuracy: 0.938333
Stop random regrow in the last batch 10 of the last epoch 54
Epoch 10 Loss: 1.491742 Validation Accuracy: 0.941667
Test accuracy of the final network: 0.962
Statistic of the proposed dynamic method:
The SVM accuracy is 0.923 for 100 features in sparse network
Statistic of the static method:
The SVM accuracy is 0.921 for 100 features in sparse network
Statistic of the QS method:
The SVM accuracy is 0.918 for 100 features in sparse network
