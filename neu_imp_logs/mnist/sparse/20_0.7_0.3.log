*************************************************arguments*************************************************
Namespace(alpha=0.3, batch=45, batch_update=False, beta=0.7, class_sep=1.0, dataset='mnist', detail=False, device='cpu', epoch=100, epsilon=20, evaluating_batch_size=10000, flip_y=0.01, hidden_dim=1000, input_dim=784, k_list=[100], logs_name='./neu_imp_logs/mnist/sparse/20_0.7_0.3.log', lr=0.001, n_classes=2, n_clusters_per_class=1, n_features=500, n_informative=5, n_redundant=15, n_samples=1000, network='sparse', num_testing=1000, num_training=4500, num_validation=500, output_dim=10, random_state=0, repeat=1, results_name='./neu_imp_results/mnist/sparse/20_0.7_0.3.json', seeds=[0, 1, 2, 3, 4], shuffle=False, training_batch_size=100, use_seeds=False)
*************************************************Repeat 1*************************************************
Neural Network:
fc1.weight number of parameters(dense counterpart):784000 number of parameters(network topology):35478 density:0.045510 sparsity:0.954490
fc2.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):39986 density:0.040000 sparsity:0.960000
fc3.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):40182 density:0.040000 sparsity:0.960000
fc4.weight number of parameters(dense counterpart):10000 number of parameters(network topology):10000 density:1.000000 sparsity:0.000000
the entire network number of parameters(dense counterpart):2794000 number of parameters(network topology):125646 overall density:0.044970 overall sparsity:0.955030
successfully initialize neuron importance scores for every input neurons.
Epoch 1 Loss: 1.558782 Validation Accuracy: 0.792000
Epoch 2 Loss: 1.508518 Validation Accuracy: 0.944000
Epoch 3 Loss: 1.487764 Validation Accuracy: 0.950000
Epoch 4 Loss: 1.486286 Validation Accuracy: 0.954000
Epoch 5 Loss: 1.481725 Validation Accuracy: 0.946000
Epoch 6 Loss: 1.481068 Validation Accuracy: 0.946000
Epoch 7 Loss: 1.479097 Validation Accuracy: 0.952000
Epoch 8 Loss: 1.462609 Validation Accuracy: 0.956000
Epoch 9 Loss: 1.461828 Validation Accuracy: 0.960000
Epoch 10 Loss: 1.461840 Validation Accuracy: 0.958000
Epoch 11 Loss: 1.461515 Validation Accuracy: 0.954000
Epoch 12 Loss: 1.461728 Validation Accuracy: 0.958000
Epoch 13 Loss: 1.462157 Validation Accuracy: 0.948000
Epoch 14 Loss: 1.461439 Validation Accuracy: 0.956000
Epoch 15 Loss: 1.462861 Validation Accuracy: 0.934000
Epoch 16 Loss: 1.486802 Validation Accuracy: 0.932000
Epoch 17 Loss: 1.495275 Validation Accuracy: 0.928000
Epoch 18 Loss: 1.476860 Validation Accuracy: 0.938000
Epoch 19 Loss: 1.478178 Validation Accuracy: 0.946000
Epoch 20 Loss: 1.468820 Validation Accuracy: 0.940000
Epoch 21 Loss: 1.469091 Validation Accuracy: 0.948000
Epoch 22 Loss: 1.461273 Validation Accuracy: 0.954000
Epoch 23 Loss: 1.461251 Validation Accuracy: 0.954000
Epoch 24 Loss: 1.461215 Validation Accuracy: 0.954000
Epoch 25 Loss: 1.461205 Validation Accuracy: 0.954000
Epoch 26 Loss: 1.461200 Validation Accuracy: 0.956000
Epoch 27 Loss: 1.461193 Validation Accuracy: 0.956000
Epoch 28 Loss: 1.461191 Validation Accuracy: 0.956000
Epoch 29 Loss: 1.461186 Validation Accuracy: 0.956000
Epoch 30 Loss: 1.461185 Validation Accuracy: 0.956000
Epoch 31 Loss: 1.461182 Validation Accuracy: 0.956000
Epoch 32 Loss: 1.461180 Validation Accuracy: 0.956000
Epoch 33 Loss: 1.461179 Validation Accuracy: 0.958000
Epoch 34 Loss: 1.461187 Validation Accuracy: 0.956000
Epoch 35 Loss: 1.461179 Validation Accuracy: 0.958000
Epoch 36 Loss: 1.461176 Validation Accuracy: 0.956000
Epoch 37 Loss: 1.461174 Validation Accuracy: 0.956000
Epoch 38 Loss: 1.461173 Validation Accuracy: 0.956000
Epoch 39 Loss: 1.461172 Validation Accuracy: 0.958000
Epoch 40 Loss: 1.461171 Validation Accuracy: 0.956000
Epoch 41 Loss: 1.461170 Validation Accuracy: 0.956000
Epoch 42 Loss: 1.461169 Validation Accuracy: 0.956000
Epoch 43 Loss: 1.461168 Validation Accuracy: 0.956000
Epoch 44 Loss: 1.461168 Validation Accuracy: 0.956000
Epoch 45 Loss: 1.461167 Validation Accuracy: 0.956000
Epoch 46 Loss: 1.461167 Validation Accuracy: 0.958000
Epoch 47 Loss: 1.461166 Validation Accuracy: 0.958000
Epoch 48 Loss: 1.461165 Validation Accuracy: 0.956000
Epoch 49 Loss: 1.461165 Validation Accuracy: 0.956000
Epoch 50 Loss: 1.461164 Validation Accuracy: 0.956000
Epoch 51 Loss: 1.461163 Validation Accuracy: 0.956000
Epoch 52 Loss: 1.461162 Validation Accuracy: 0.958000
Epoch 53 Loss: 1.461162 Validation Accuracy: 0.958000
Epoch 54 Loss: 1.461162 Validation Accuracy: 0.956000
Epoch 55 Loss: 1.461162 Validation Accuracy: 0.958000
Epoch 56 Loss: 1.461162 Validation Accuracy: 0.958000
Epoch 57 Loss: 1.461161 Validation Accuracy: 0.958000
Epoch 58 Loss: 1.461160 Validation Accuracy: 0.956000
Epoch 59 Loss: 1.461161 Validation Accuracy: 0.958000
Epoch 60 Loss: 1.461160 Validation Accuracy: 0.958000
Epoch 61 Loss: 1.461159 Validation Accuracy: 0.958000
Epoch 62 Loss: 1.461159 Validation Accuracy: 0.956000
Epoch 63 Loss: 1.461158 Validation Accuracy: 0.956000
Epoch 64 Loss: 1.461159 Validation Accuracy: 0.956000
Epoch 65 Loss: 1.461159 Validation Accuracy: 0.956000
Epoch 66 Loss: 1.461158 Validation Accuracy: 0.956000
Epoch 67 Loss: 1.461158 Validation Accuracy: 0.956000
Epoch 68 Loss: 1.461158 Validation Accuracy: 0.956000
Epoch 69 Loss: 1.461157 Validation Accuracy: 0.956000
Epoch 70 Loss: 1.461157 Validation Accuracy: 0.956000
Epoch 71 Loss: 1.461157 Validation Accuracy: 0.956000
Epoch 72 Loss: 1.461157 Validation Accuracy: 0.956000
Epoch 73 Loss: 1.461157 Validation Accuracy: 0.956000
Epoch 74 Loss: 1.461157 Validation Accuracy: 0.956000
Epoch 75 Loss: 1.461156 Validation Accuracy: 0.956000
Epoch 76 Loss: 1.461157 Validation Accuracy: 0.958000
Epoch 77 Loss: 1.461156 Validation Accuracy: 0.958000
Epoch 78 Loss: 1.461156 Validation Accuracy: 0.958000
Epoch 79 Loss: 1.461156 Validation Accuracy: 0.958000
Epoch 80 Loss: 1.461156 Validation Accuracy: 0.958000
Epoch 81 Loss: 1.461156 Validation Accuracy: 0.956000
Epoch 82 Loss: 1.461156 Validation Accuracy: 0.956000
Epoch 83 Loss: 1.461155 Validation Accuracy: 0.956000
Epoch 84 Loss: 1.461155 Validation Accuracy: 0.956000
Epoch 85 Loss: 1.461155 Validation Accuracy: 0.958000
Epoch 86 Loss: 1.461156 Validation Accuracy: 0.958000
Epoch 87 Loss: 1.461156 Validation Accuracy: 0.958000
Epoch 88 Loss: 1.461155 Validation Accuracy: 0.960000
Epoch 89 Loss: 1.461155 Validation Accuracy: 0.960000
Epoch 90 Loss: 1.461155 Validation Accuracy: 0.960000
Epoch 91 Loss: 1.461155 Validation Accuracy: 0.960000
Epoch 92 Loss: 1.461154 Validation Accuracy: 0.960000
Epoch 93 Loss: 1.461154 Validation Accuracy: 0.960000
Epoch 94 Loss: 1.461154 Validation Accuracy: 0.960000
Epoch 95 Loss: 1.461154 Validation Accuracy: 0.958000
Epoch 96 Loss: 1.461155 Validation Accuracy: 0.956000
Epoch 97 Loss: 1.461155 Validation Accuracy: 0.956000
Epoch 98 Loss: 1.461154 Validation Accuracy: 0.956000
Epoch 99 Loss: 1.461154 Validation Accuracy: 0.956000
Stop random regrow in the last batch 100 of the last epoch 45
Epoch 100 Loss: 1.461154 Validation Accuracy: 0.956000
Test accuracy of the final network: 0.96
Statistic of the proposed dynamic method:
The SVM accuracy is 0.906 for 100 features in sparse network
Statistic of the static method:
The SVM accuracy is 0.908 for 100 features in sparse network
Statistic of the QS method:
The SVM accuracy is 0.852 for 100 features in sparse network
