*************************************************arguments*************************************************
Namespace(alpha=0.3, batch=18, batch_update=False, beta=0.7, class_sep=1.0, dataset='madelon', detail=False, device='cpu', epoch=100, epsilon=1, evaluating_batch_size=10000, flip_y=0.01, hidden_dim=1000, input_dim=500, k_list=[100], logs_name='./neu_imp_logs/madelon/sparse/1_0.7_0.3.log', lr=0.001, n_classes=2, n_clusters_per_class=1, n_features=500, n_informative=5, n_redundant=15, n_samples=1000, network='sparse', num_testing=600, num_training=1800, num_validation=200, output_dim=2, random_state=0, repeat=1, results_name='./neu_imp_results/madelon/sparse/1_0.7_0.3.json', seeds=[0, 1, 2, 3, 4], shuffle=False, training_batch_size=100, use_seeds=False)
*************************************************Repeat 1*************************************************
Neural Network:
fc1.weight number of parameters(dense counterpart):500000 number of parameters(network topology):1484 density:0.003000 sparsity:0.997000
fc2.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):1950 density:0.002000 sparsity:0.998000
fc3.weight number of parameters(dense counterpart):1000000 number of parameters(network topology):1974 density:0.002000 sparsity:0.998000
fc4.weight number of parameters(dense counterpart):2000 number of parameters(network topology):1022 density:0.501000 sparsity:0.499000
the entire network number of parameters(dense counterpart):2502000 number of parameters(network topology):6430 overall density:0.002570 overall sparsity:0.997430
successfully initialize neuron importance scores for every input neurons.
Epoch 1 Loss: 0.692864 Validation Accuracy: 0.520000
Epoch 2 Loss: 0.661762 Validation Accuracy: 0.520000
Epoch 3 Loss: 0.639259 Validation Accuracy: 0.535000
Epoch 4 Loss: 0.627842 Validation Accuracy: 0.580000
Epoch 5 Loss: 0.607229 Validation Accuracy: 0.615000
Epoch 6 Loss: 0.589623 Validation Accuracy: 0.590000
Epoch 7 Loss: 0.572040 Validation Accuracy: 0.610000
Epoch 8 Loss: 0.554929 Validation Accuracy: 0.575000
Epoch 9 Loss: 0.550252 Validation Accuracy: 0.555000
Epoch 10 Loss: 0.531540 Validation Accuracy: 0.565000
Epoch 11 Loss: 0.522255 Validation Accuracy: 0.620000
Epoch 12 Loss: 0.510664 Validation Accuracy: 0.620000
Epoch 13 Loss: 0.499788 Validation Accuracy: 0.585000
Epoch 14 Loss: 0.489004 Validation Accuracy: 0.600000
Epoch 15 Loss: 0.480592 Validation Accuracy: 0.585000
Epoch 16 Loss: 0.461900 Validation Accuracy: 0.580000
Epoch 17 Loss: 0.457157 Validation Accuracy: 0.605000
Epoch 18 Loss: 0.440288 Validation Accuracy: 0.575000
Epoch 19 Loss: 0.443433 Validation Accuracy: 0.570000
Epoch 20 Loss: 0.430544 Validation Accuracy: 0.580000
Epoch 21 Loss: 0.422071 Validation Accuracy: 0.600000
Epoch 22 Loss: 0.420324 Validation Accuracy: 0.580000
Epoch 23 Loss: 0.412111 Validation Accuracy: 0.570000
Epoch 24 Loss: 0.414002 Validation Accuracy: 0.565000
Epoch 25 Loss: 0.409212 Validation Accuracy: 0.555000
Epoch 26 Loss: 0.398311 Validation Accuracy: 0.575000
Epoch 27 Loss: 0.400338 Validation Accuracy: 0.590000
Epoch 28 Loss: 0.393266 Validation Accuracy: 0.550000
Epoch 29 Loss: 0.387505 Validation Accuracy: 0.560000
Epoch 30 Loss: 0.391317 Validation Accuracy: 0.570000
Epoch 31 Loss: 0.381121 Validation Accuracy: 0.540000
Epoch 32 Loss: 0.384744 Validation Accuracy: 0.580000
Epoch 33 Loss: 0.372486 Validation Accuracy: 0.565000
Epoch 34 Loss: 0.377687 Validation Accuracy: 0.565000
Epoch 35 Loss: 0.368820 Validation Accuracy: 0.570000
Epoch 36 Loss: 0.364180 Validation Accuracy: 0.585000
Epoch 37 Loss: 0.366839 Validation Accuracy: 0.590000
Epoch 38 Loss: 0.362336 Validation Accuracy: 0.600000
Epoch 39 Loss: 0.359744 Validation Accuracy: 0.595000
Epoch 40 Loss: 0.360876 Validation Accuracy: 0.585000
Epoch 41 Loss: 0.358343 Validation Accuracy: 0.595000
Epoch 42 Loss: 0.353536 Validation Accuracy: 0.600000
Epoch 43 Loss: 0.351670 Validation Accuracy: 0.605000
Epoch 44 Loss: 0.350866 Validation Accuracy: 0.590000
Epoch 45 Loss: 0.350472 Validation Accuracy: 0.600000
Epoch 46 Loss: 0.348139 Validation Accuracy: 0.595000
Epoch 47 Loss: 0.345440 Validation Accuracy: 0.590000
Epoch 48 Loss: 0.345972 Validation Accuracy: 0.585000
Epoch 49 Loss: 0.343896 Validation Accuracy: 0.600000
Epoch 50 Loss: 0.344559 Validation Accuracy: 0.590000
Epoch 51 Loss: 0.339726 Validation Accuracy: 0.580000
Epoch 52 Loss: 0.339142 Validation Accuracy: 0.580000
Epoch 53 Loss: 0.336640 Validation Accuracy: 0.575000
Epoch 54 Loss: 0.336010 Validation Accuracy: 0.575000
Epoch 55 Loss: 0.337084 Validation Accuracy: 0.595000
Epoch 56 Loss: 0.334405 Validation Accuracy: 0.590000
Epoch 57 Loss: 0.335383 Validation Accuracy: 0.580000
Epoch 58 Loss: 0.331634 Validation Accuracy: 0.580000
Epoch 59 Loss: 0.333986 Validation Accuracy: 0.570000
Epoch 60 Loss: 0.331601 Validation Accuracy: 0.585000
Epoch 61 Loss: 0.332171 Validation Accuracy: 0.585000
Epoch 62 Loss: 0.330794 Validation Accuracy: 0.575000
Epoch 63 Loss: 0.329387 Validation Accuracy: 0.580000
Epoch 64 Loss: 0.329688 Validation Accuracy: 0.570000
Epoch 65 Loss: 0.327891 Validation Accuracy: 0.570000
Epoch 66 Loss: 0.328546 Validation Accuracy: 0.570000
Epoch 67 Loss: 0.327867 Validation Accuracy: 0.570000
Epoch 68 Loss: 0.327766 Validation Accuracy: 0.585000
Epoch 69 Loss: 0.325843 Validation Accuracy: 0.580000
Epoch 70 Loss: 0.326758 Validation Accuracy: 0.570000
Epoch 71 Loss: 0.325922 Validation Accuracy: 0.580000
Epoch 72 Loss: 0.325400 Validation Accuracy: 0.570000
Epoch 73 Loss: 0.324662 Validation Accuracy: 0.560000
Epoch 74 Loss: 0.325147 Validation Accuracy: 0.565000
Epoch 75 Loss: 0.323848 Validation Accuracy: 0.580000
Epoch 76 Loss: 0.324631 Validation Accuracy: 0.585000
Epoch 77 Loss: 0.323711 Validation Accuracy: 0.575000
Epoch 78 Loss: 0.322915 Validation Accuracy: 0.580000
Epoch 79 Loss: 0.322868 Validation Accuracy: 0.580000
Epoch 80 Loss: 0.322717 Validation Accuracy: 0.580000
Epoch 81 Loss: 0.322515 Validation Accuracy: 0.575000
Epoch 82 Loss: 0.322559 Validation Accuracy: 0.580000
Epoch 83 Loss: 0.322219 Validation Accuracy: 0.580000
Epoch 84 Loss: 0.321988 Validation Accuracy: 0.575000
Epoch 85 Loss: 0.321203 Validation Accuracy: 0.580000
Epoch 86 Loss: 0.320962 Validation Accuracy: 0.580000
Epoch 87 Loss: 0.321184 Validation Accuracy: 0.580000
Epoch 88 Loss: 0.320580 Validation Accuracy: 0.580000
Epoch 89 Loss: 0.320434 Validation Accuracy: 0.575000
Epoch 90 Loss: 0.320438 Validation Accuracy: 0.575000
Epoch 91 Loss: 0.320318 Validation Accuracy: 0.580000
Epoch 92 Loss: 0.319320 Validation Accuracy: 0.575000
Epoch 93 Loss: 0.319962 Validation Accuracy: 0.575000
Epoch 94 Loss: 0.318829 Validation Accuracy: 0.575000
Epoch 95 Loss: 0.319424 Validation Accuracy: 0.575000
Epoch 96 Loss: 0.319067 Validation Accuracy: 0.575000
Epoch 97 Loss: 0.319402 Validation Accuracy: 0.575000
Epoch 98 Loss: 0.318579 Validation Accuracy: 0.580000
Epoch 99 Loss: 0.318545 Validation Accuracy: 0.590000
Stop random regrow in the last batch 100 of the last epoch 18
Epoch 100 Loss: 0.318922 Validation Accuracy: 0.575000
Test accuracy of the final network: 0.5966666666666667
Statistic of the proposed dynamic method:
The SVM accuracy is 0.605 for 100 features in sparse network
Statistic of the static method:
The SVM accuracy is 0.5816666666666667 for 100 features in sparse network
Statistic of the QS method:
The SVM accuracy is 0.5666666666666667 for 100 features in sparse network
